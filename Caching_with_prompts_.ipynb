{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install chromadb\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "nC7JTl_FdFX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "2ItlXLzHdtzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "\n",
        "class PromptCacher:\n",
        "    def __init__(self, cache_file='prompts_and_answers.json'):\n",
        "        \"\"\"\n",
        "        Initializes the PromptCacher class with a cache file.\n",
        "\n",
        "        Args:\n",
        "            cache_file (str): The filename to use for caching prompts and answers.\n",
        "        \"\"\"\n",
        "        self.cache_file = cache_file\n",
        "        self.cache = self.load_cache()\n",
        "\n",
        "    def load_cache(self):\n",
        "        \"\"\"\n",
        "        Loads cached prompts and answers from a JSON file.\n",
        "\n",
        "        Returns:\n",
        "            dict: The cached prompts and answers.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            with open(self.cache_file, 'r') as file:\n",
        "                return json.load(file)\n",
        "        except FileNotFoundError:\n",
        "            return {}\n",
        "\n",
        "    def save_cache(self):\n",
        "        \"\"\"\n",
        "        Saves the cached prompts and answers to a JSON file.\n",
        "        \"\"\"\n",
        "        with open(self.cache_file, 'w') as file:\n",
        "            json.dump(self.cache, file, indent=2)\n",
        "\n",
        "    def get_answer(self, prompt):\n",
        "        \"\"\"\n",
        "        Retrieves an answer from cache if available, otherwise prompts the user for an answer.\n",
        "\n",
        "        Args:\n",
        "            prompt (str): The prompt for which to retrieve an answer.\n",
        "\n",
        "        Returns:\n",
        "            str: The answer corresponding to the prompt.\n",
        "        \"\"\"\n",
        "        if prompt in self.cache:\n",
        "            return self.cache[prompt]\n",
        "        else:\n",
        "            answer = input(f\"Prompt: {prompt}\\nEnter answer: \")\n",
        "            self.cache[prompt] = answer\n",
        "            self.save_cache()\n",
        "            return answer\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to interact with the PromptCacher class.\n",
        "    \"\"\"\n",
        "    prompt_cacher = PromptCacher()\n",
        "\n",
        "    while True:\n",
        "        user_prompt = input(\"Enter a prompt (type 'exit' to end): \")\n",
        "        if user_prompt.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        answer = prompt_cacher.get_answer(user_prompt)\n",
        "        print(f\"Answer: {answer}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "bg-qG90HvpWf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}